#!/usr/bin/env python3
"""
æ•°æ®ç»Ÿè®¡åˆ†æè„šæœ¬
åˆ†æ tasks.csv å’Œ task_kb.jsonl çš„å†…å®¹ç»Ÿè®¡
"""

import csv
import json
import os
from collections import Counter, defaultdict
from typing import Dict, List, Any

def analyze_tasks_csv(file_path: str) -> Dict[str, Any]:
    """åˆ†æä»»åŠ¡ CSV æ–‡ä»¶"""
    stats = {
        'total_tasks': 0,
        'categories': Counter(),
        'difficulties': Counter(),
        'statuses': Counter(),
        'courses': Counter(),
        'avg_duration': 0,
        'duration_range': {'min': float('inf'), 'max': 0},
        'locations': set(),
        'npcs': set()
    }
    
    total_duration = 0
    
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            stats['total_tasks'] += 1
            
            # ç»Ÿè®¡åˆ†ç±»
            stats['categories'][row.get('category', 'Unknown')] += 1
            
            # ç»Ÿè®¡éš¾åº¦
            stats['difficulties'][row.get('difficulty', 'Unknown')] += 1
            
            # ç»Ÿè®¡çŠ¶æ€
            stats['statuses'][row.get('status', 'Unknown')] += 1
            
            # ç»Ÿè®¡è¯¾ç¨‹
            course = row.get('course_code', '').strip()
            if course:
                stats['courses'][course] += 1
            else:
                stats['courses']['æ— è¯¾ç¨‹å…³è”'] += 1
            
            # ç»Ÿè®¡æ—¶é•¿
            try:
                duration = int(row.get('estimated_duration', 0))
                total_duration += duration
                stats['duration_range']['min'] = min(stats['duration_range']['min'], duration)
                stats['duration_range']['max'] = max(stats['duration_range']['max'], duration)
            except ValueError:
                pass
            
            # ç»Ÿè®¡åœ°ç‚¹å’ŒNPC
            stats['locations'].add(row.get('location_name', 'Unknown'))
            stats['npcs'].add(row.get('npc_id', 'Unknown'))
    
    if stats['total_tasks'] > 0:
        stats['avg_duration'] = total_duration / stats['total_tasks']
    
    # è½¬æ¢é›†åˆä¸ºè®¡æ•°
    stats['unique_locations'] = len(stats['locations'])
    stats['unique_npcs'] = len(stats['npcs'])
    del stats['locations']
    del stats['npcs']
    
    return stats

def analyze_task_kb_jsonl(file_path: str) -> Dict[str, Any]:
    """åˆ†æä»»åŠ¡çŸ¥è¯†åº“ JSONL æ–‡ä»¶"""
    stats = {
        'total_records': 0,
        'knowledge_types': Counter(),
        'difficulties': Counter(),
        'avg_content_length': 0,
        'content_length_range': {'min': float('inf'), 'max': 0},
        'avg_tags_count': 0,
        'all_tags': Counter(),
        'courses': Counter(),
        'avg_estimated_time': 0
    }
    
    total_content_length = 0
    total_tags_count = 0
    total_estimated_time = 0
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
                
            try:
                data = json.loads(line)
                stats['total_records'] += 1
                
                # ç»Ÿè®¡çŸ¥è¯†ç±»å‹
                stats['knowledge_types'][data.get('knowledge_type', 'Unknown')] += 1
                
                # ç»Ÿè®¡éš¾åº¦
                stats['difficulties'][data.get('difficulty', 'Unknown')] += 1
                
                # ç»Ÿè®¡å†…å®¹é•¿åº¦
                content = data.get('content', '')
                content_length = len(content)
                total_content_length += content_length
                stats['content_length_range']['min'] = min(stats['content_length_range']['min'], content_length)
                stats['content_length_range']['max'] = max(stats['content_length_range']['max'], content_length)
                
                # ç»Ÿè®¡æ ‡ç­¾
                tags = data.get('tags', [])
                if isinstance(tags, list):
                    total_tags_count += len(tags)
                    for tag in tags:
                        stats['all_tags'][tag] += 1
                
                # ç»Ÿè®¡è¯¾ç¨‹
                course = data.get('course_code')
                if course:
                    stats['courses'][course] += 1
                else:
                    stats['courses']['æ— è¯¾ç¨‹å…³è”'] += 1
                
                # ç»Ÿè®¡é¢„ä¼°æ—¶é—´
                estimated_time = data.get('estimated_time', 0)
                if isinstance(estimated_time, int):
                    total_estimated_time += estimated_time
                    
            except json.JSONDecodeError:
                continue
    
    if stats['total_records'] > 0:
        stats['avg_content_length'] = total_content_length / stats['total_records']
        stats['avg_tags_count'] = total_tags_count / stats['total_records']
        stats['avg_estimated_time'] = total_estimated_time / stats['total_records']
    
    return stats

def print_stats():
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“Š CityU Campus Tasks - æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("=" * 60)
    
    # è·å–æ–‡ä»¶è·¯å¾„
    data_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data')
    csv_file = os.path.join(data_dir, 'tasks.csv')
    jsonl_file = os.path.join(data_dir, 'task_kb.jsonl')
    
    # åˆ†æä»»åŠ¡æ•°æ®
    print("\nğŸ¯ ä»»åŠ¡æ•°æ®ç»Ÿè®¡ (tasks.csv)")
    print("-" * 40)
    
    if os.path.exists(csv_file):
        task_stats = analyze_tasks_csv(csv_file)
        
        print(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {task_stats['total_tasks']}")
        print(f"â±ï¸  å¹³å‡æ—¶é•¿: {task_stats['avg_duration']:.1f} åˆ†é’Ÿ")
        print(f"ğŸ“ ç‹¬ç‰¹åœ°ç‚¹: {task_stats['unique_locations']} ä¸ª")
        print(f"ğŸ¤– å…³è”NPC: {task_stats['unique_npcs']} ä¸ª")
        
        print(f"\nğŸ“‚ ä»»åŠ¡åˆ†ç±»åˆ†å¸ƒ:")
        for category, count in task_stats['categories'].most_common():
            percentage = (count / task_stats['total_tasks']) * 100
            print(f"  {category}: {count} ({percentage:.1f}%)")
        
        print(f"\nâ­ éš¾åº¦åˆ†å¸ƒ:")
        for difficulty, count in task_stats['difficulties'].most_common():
            percentage = (count / task_stats['total_tasks']) * 100
            print(f"  {difficulty}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸ“š è¯¾ç¨‹å…³è”:")
        for course, count in task_stats['courses'].most_common():
            percentage = (count / task_stats['total_tasks']) * 100
            print(f"  {course}: {count} ({percentage:.1f}%)")
            
        print(f"\nâ° æ—¶é•¿èŒƒå›´: {task_stats['duration_range']['min']}-{task_stats['duration_range']['max']} åˆ†é’Ÿ")
    else:
        print("âŒ tasks.csv æ–‡ä»¶ä¸å­˜åœ¨")
    
    # åˆ†æçŸ¥è¯†åº“æ•°æ®
    print("\nğŸ“š çŸ¥è¯†åº“æ•°æ®ç»Ÿè®¡ (task_kb.jsonl)")
    print("-" * 40)
    
    if os.path.exists(jsonl_file):
        kb_stats = analyze_task_kb_jsonl(jsonl_file)
        
        print(f"ğŸ“– æ€»çŸ¥è¯†æ¡ç›®: {kb_stats['total_records']}")
        print(f"ğŸ“ å¹³å‡å†…å®¹é•¿åº¦: {kb_stats['avg_content_length']:.1f} å­—ç¬¦")
        print(f"ğŸ·ï¸  å¹³å‡æ ‡ç­¾æ•°: {kb_stats['avg_tags_count']:.1f} ä¸ª")
        print(f"â±ï¸  å¹³å‡å­¦ä¹ æ—¶é—´: {kb_stats['avg_estimated_time']:.1f} åˆ†é’Ÿ")
        
        print(f"\nğŸ“‹ çŸ¥è¯†ç±»å‹åˆ†å¸ƒ:")
        for knowledge_type, count in kb_stats['knowledge_types'].most_common():
            percentage = (count / kb_stats['total_records']) * 100
            print(f"  {knowledge_type}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸ·ï¸  çƒ­é—¨æ ‡ç­¾ (Top 10):")
        for tag, count in kb_stats['all_tags'].most_common(10):
            percentage = (count / kb_stats['total_records']) * 100
            print(f"  {tag}: {count} ({percentage:.1f}%)")
        
        print(f"\nğŸ“š è¯¾ç¨‹å…³è”:")
        for course, count in kb_stats['courses'].most_common():
            percentage = (count / kb_stats['total_records']) * 100
            print(f"  {course}: {count} ({percentage:.1f}%)")
            
        print(f"\nğŸ“ å†…å®¹é•¿åº¦èŒƒå›´: {kb_stats['content_length_range']['min']}-{kb_stats['content_length_range']['max']} å­—ç¬¦")
    else:
        print("âŒ task_kb.jsonl æ–‡ä»¶ä¸å­˜åœ¨")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    print("\nğŸ” æ•°æ®è´¨é‡è¯„ä¼°")
    print("-" * 40)
    
    if os.path.exists(csv_file) and os.path.exists(jsonl_file):
        task_stats = analyze_tasks_csv(csv_file)
        kb_stats = analyze_task_kb_jsonl(jsonl_file)
        
        # æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        if task_stats['total_tasks'] == kb_stats['total_records']:
            print("âœ… ä»»åŠ¡æ•°æ®ä¸çŸ¥è¯†åº“æ•°æ®æ•°é‡ä¸€è‡´")
        else:
            print(f"âš ï¸  æ•°æ®æ•°é‡ä¸ä¸€è‡´: ä»»åŠ¡({task_stats['total_tasks']}) vs çŸ¥è¯†åº“({kb_stats['total_records']})")
        
        # æ£€æŸ¥è¯¾ç¨‹è¦†ç›–
        course_tasks = sum(1 for course in task_stats['courses'] if course != 'æ— è¯¾ç¨‹å…³è”')
        course_percentage = (course_tasks / task_stats['total_tasks']) * 100
        print(f"ğŸ“š è¯¾ç¨‹å…³è”è¦†ç›–ç‡: {course_percentage:.1f}%")
        
        # æ£€æŸ¥éš¾åº¦åˆ†å¸ƒ
        difficulty_balance = max(task_stats['difficulties'].values()) / min(task_stats['difficulties'].values())
        if difficulty_balance <= 2:
            print("âœ… éš¾åº¦åˆ†å¸ƒç›¸å¯¹å‡è¡¡")
        else:
            print("âš ï¸  éš¾åº¦åˆ†å¸ƒä¸å‡è¡¡ï¼Œå»ºè®®è°ƒæ•´")
    
    print("\nğŸ¯ æ•°æ®æ¦‚è§ˆå®Œæˆ!")

if __name__ == "__main__":
    print_stats()